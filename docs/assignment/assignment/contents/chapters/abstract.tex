

\begin{abstract}

\begin{multicols}{2}
% Das vorliegende Dokument beschreibt das Produkt SmartCart des Teams
% IoT-Designers. Das Ziel der Anwendung ist es einen smarter Way of
% Shopping zu ermöglichen. The application offers the possibility of easily
% marking items as added to the cart and the navigating through a list via
% gestures, um den User beim Eimkaufen zu unterstüzten und entlasten. Therefore,
% the recognition of gestures is done via the built-in acceleration sensor in
% combination with the magnetic field sensor.

% Anstatt umständlich mit Stift und Papier die Einkaufsliste abzuarbeiten soll
% diese App durch die Gesternsteuerung erleichertern. Dabei fokusiert sich diese
% App auf zwei use cases welche dem Benutzer angeboten werden. Dem Benutzer soll
% es ermöglicht werden mit einer Hand und einfachen jedoch eindeutigen Gesten
% sowohl zwischen den Items in der Einkaufsliste hin und her zu wechseln als auch
% die bereits gefundenen Items abzuhaken.

% To recognize the chosen gestures, the acceleration sensor and the magnetic field sensor are
% used. The retrieved acceleration values are used to determine the movement that
% is made. The magnetic field sensor sensor serves to recognize the orientation of the
% smartphone and to be able to subtract out its influence out of the acceleration
% values.

% Um aus den von den Sensoren erhaltenen Werten Gesten abzuleiten wurden zunächst
% Daten erfasst, welche die jeweilige Gesten wiederspiegeln. Damit die
% verschiedenen Sensorwerte zuordbar sind, wurden mehrere Messungen durchgeführt.
% Damit die Gesten, möglichst unabhängig von der Ausrichtung des Mobile Phones
% durchführbar sind, werden verschiedene mathematischen Berechnungen benötigt.

% Das Ende dieses Dokuments beschreibt das Ergebnis der App sowie deren Nutzung.
The present document describes the product SmartCart of the team IoT-Designers.
The aim of the application is to offer a smarter way of shopping to its users.
The application offers the possibility to easily mark items as added to the
cart and to navigate through a list via gestures in order to support and
relieve the user during shopping. The recognition of gestures is done
by the built-in acceleration sensor in combination with the magnetic field
sensor.

Instead of handling a shopping list with the help of pen and paper or by
pushing buttons on a virtual list, this app easies the whole process via
gesture control.
The main focus is placed on two use cases offered to the app's user:
switching between the items in the shopping list as well as to check off the
already found items with only one hand and simple but unambiguous gestures. 

%To recognize the chosen gestures, the acceleration sensor and the magnetic
% field sensor are used. 
The retrieved acceleration values from the acceleration sensor are used to
determine the movement that is made. The magnetic field sensor serves to 
recognize the orientation of the smartphone and is able to subtract its
influence out of the acceleration values.

In order to derive gestures from the values obtained by the sensors, data,
which reflects the respective gestures, will be acquired in the first step.
Various measurements are carried out to link the different sensor values to
their correlating gesture. In order to carry out the gesture recognition, the
values of the magnetic field sensor are set against the retrieved acceleration
values in the final step. The gesture recognition is independent of the
orientation of the mobile phone.

The end of this document describes the results of the application and how to use
it.

\end{multicols}
\end{abstract}